{"nbformat_minor": 1, "cells": [{"execution_count": 1, "cell_type": "code", "metadata": {}, "outputs": [], "source": "# The code was removed by Watson Studio for sharing."}, {"source": "# Predicting English Premier League Matches", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "By: Yi Xuan Sim", "cell_type": "markdown", "metadata": {}}, {"source": "## Model Definition, Model Training and Model Evaluation", "cell_type": "markdown", "metadata": {}}, {"source": "Loading the dataset with new features", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "metadata": {}, "outputs": [{"execution_count": 2, "metadata": {}, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTR</th>\n      <th>home_attack_score_analysis</th>\n      <th>away_attack_score_analysis</th>\n      <th>home_defense_score_analysis</th>\n      <th>away_defense_score_analysis</th>\n      <th>home_attack_efficiency_analysis</th>\n      <th>away_attack_efficiency_analysis</th>\n      <th>home_inv_defense_efficiency_analysis</th>\n      <th>away_inv_defense_efficiency_analysis</th>\n      <th>diff_attack</th>\n      <th>diff_defense</th>\n      <th>overall_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aston Villa</td>\n      <td>Bolton</td>\n      <td>D</td>\n      <td>-0.367044</td>\n      <td>-0.097585</td>\n      <td>-0.143126</td>\n      <td>0.377551</td>\n      <td>-0.241390</td>\n      <td>-0.463096</td>\n      <td>-0.722440</td>\n      <td>-0.621563</td>\n      <td>-0.269459</td>\n      <td>0.520677</td>\n      <td>0.251218</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Everton</td>\n      <td>Man United</td>\n      <td>A</td>\n      <td>0.855378</td>\n      <td>2.162607</td>\n      <td>-0.614336</td>\n      <td>-2.168971</td>\n      <td>0.418593</td>\n      <td>0.998026</td>\n      <td>-0.438074</td>\n      <td>-1.517423</td>\n      <td>-1.307229</td>\n      <td>-1.554635</td>\n      <td>-2.861864</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fulham</td>\n      <td>Birmingham</td>\n      <td>D</td>\n      <td>0.076383</td>\n      <td>-0.544953</td>\n      <td>0.074727</td>\n      <td>0.420843</td>\n      <td>-0.483306</td>\n      <td>-1.066144</td>\n      <td>-0.439501</td>\n      <td>-1.018328</td>\n      <td>0.621337</td>\n      <td>0.346116</td>\n      <td>0.967453</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Man City</td>\n      <td>West Brom</td>\n      <td>D</td>\n      <td>2.167449</td>\n      <td>-0.614544</td>\n      <td>-1.192720</td>\n      <td>-0.411329</td>\n      <td>1.120426</td>\n      <td>-0.396703</td>\n      <td>-0.398956</td>\n      <td>-0.544577</td>\n      <td>2.781993</td>\n      <td>0.781391</td>\n      <td>3.563383</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Middlesbrough</td>\n      <td>Liverpool</td>\n      <td>D</td>\n      <td>-0.268881</td>\n      <td>1.670617</td>\n      <td>0.067824</td>\n      <td>-1.633356</td>\n      <td>-0.334656</td>\n      <td>0.369332</td>\n      <td>-0.166129</td>\n      <td>-0.043594</td>\n      <td>-1.939499</td>\n      <td>-1.701180</td>\n      <td>-3.640678</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "        HomeTeam    AwayTeam FTR  home_attack_score_analysis  \\\n0    Aston Villa      Bolton   D                   -0.367044   \n1        Everton  Man United   A                    0.855378   \n2         Fulham  Birmingham   D                    0.076383   \n3       Man City   West Brom   D                    2.167449   \n4  Middlesbrough   Liverpool   D                   -0.268881   \n\n   away_attack_score_analysis  home_defense_score_analysis  \\\n0                   -0.097585                    -0.143126   \n1                    2.162607                    -0.614336   \n2                   -0.544953                     0.074727   \n3                   -0.614544                    -1.192720   \n4                    1.670617                     0.067824   \n\n   away_defense_score_analysis  home_attack_efficiency_analysis  \\\n0                     0.377551                        -0.241390   \n1                    -2.168971                         0.418593   \n2                     0.420843                        -0.483306   \n3                    -0.411329                         1.120426   \n4                    -1.633356                        -0.334656   \n\n   away_attack_efficiency_analysis  home_inv_defense_efficiency_analysis  \\\n0                        -0.463096                             -0.722440   \n1                         0.998026                             -0.438074   \n2                        -1.066144                             -0.439501   \n3                        -0.396703                             -0.398956   \n4                         0.369332                             -0.166129   \n\n   away_inv_defense_efficiency_analysis  diff_attack  diff_defense  \\\n0                             -0.621563    -0.269459      0.520677   \n1                             -1.517423    -1.307229     -1.554635   \n2                             -1.018328     0.621337      0.346116   \n3                             -0.544577     2.781993      0.781391   \n4                             -0.043594    -1.939499     -1.701180   \n\n   overall_score  \n0       0.251218  \n1      -2.861864  \n2       0.967453  \n3       3.563383  \n4      -3.640678  "}, "output_type": "execute_result"}], "source": "# The code was removed by Watson Studio for sharing."}, {"source": "Looking at dataset, we have several features, and we are trying to predict FTR (Full Time Result). This is a supervised learning problem. As FTR is a categorical data type, we will use a classifier to predict the outcomes. We will use 2 models, a non-deep learning based model, and a deep learning model. ", "cell_type": "markdown", "metadata": {}}, {"source": "### Non-deep learning model", "cell_type": "markdown", "metadata": {}}, {"source": "For the non-deep learning model, we will use various classifiers, such as RandomForest Classifier, SVC, and Decision Tree Classifier to predict the outcome of the match. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "metadata": {}, "outputs": [], "source": "from sklearn.ensemble import RandomForestClassifier \nfrom sklearn.svm import SVC \nfrom sklearn.tree import DecisionTreeClassifier "}, {"execution_count": 4, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"}], "source": "from sklearn.cross_validation import train_test_split #this is required to split the data into training and test data\n\n#data is split into training and testing datasets in 70:30 ratio\nx_all = df_data_1.drop(['HomeTeam','AwayTeam','FTR'], axis=1)\ny_all = df_data_1['FTR']\nx_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size = 0.30, random_state = 99)"}, {"source": "### Model Training", "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "metadata": {}, "outputs": [], "source": "#Introducing each classifier with own variables to make the next step in training easier by doing it all at once\nclf1 = RandomForestClassifier()\nclf2 = SVC()\nclf3 = DecisionTreeClassifier()"}, {"execution_count": 6, "cell_type": "code", "metadata": {}, "outputs": [], "source": "#Starting to training the data and cross validate\n\ny_pred1 = clf1.fit(x_train,y_train).predict(x_test) #fitting the training data with RandomForestClassifier\ny_pred2 = clf2.fit(x_train,y_train).predict(x_test) #fitting the training data with SVC\ny_pred3 = clf3.fit(x_train,y_train).predict(x_test) #fitting the training data with DecisionTreeClassifier"}, {"source": "### Model Evaluation", "cell_type": "markdown", "metadata": {}}, {"source": "We use 10 fold cross-validation to evaluate the model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 7, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "By predicting using all features\nAccuracy 0.47 Score 0.472 RandomForestClassifier\nAccuracy 0.52 Score 0.554 SVC\nAccuracy 0.46 Score 0.463 DecisionTreeClassifier\n"}], "source": "from sklearn.metrics import accuracy_score #to calculate the number of correct prediction against true value\nfrom sklearn.model_selection import cross_val_score #to cross validate and acts as a scoring system for classifier\n\nacc1 = accuracy_score(y_pred1,y_test)\nscores1 = cross_val_score(clf1, x_train, y_train, cv=10)\n\nacc2 = accuracy_score(y_pred2,y_test)\nscores2 = cross_val_score(clf2, x_train, y_train, cv=10)\n\nacc3 = accuracy_score(y_pred3,y_test)\nscores3 = cross_val_score(clf3, x_train, y_train, cv=10)\n\n#Getting the mean scores for the cross validation\nscores1_mean = scores1.mean()\nscores2_mean = scores2.mean()\nscores3_mean = scores3.mean()\n\nprint('By predicting using all features')\nprint(\"Accuracy\",'%.2f'%acc1, \"Score\", '%.3f'%scores1_mean,\"RandomForestClassifier\")\nprint(\"Accuracy\",'%.2f'%acc2, \"Score\", '%.3f'%scores2_mean,\"SVC\")\nprint(\"Accuracy\",'%.2f'%acc3, \"Score\", '%.3f'%scores3_mean,\"DecisionTreeClassifier\")"}, {"source": "From the results, we can see that the Random Forest Classifier and Decision Tree Classifier has an accuracy of less than 50%, while SVC provides an accuracy of 52%. We shall now use Adaboost to investigate whether it improves performance. \n\nBy default, Adaboost uses RandomForest as the base estimator. Boosting works best when paired with a non-linear model. We choose Random Forest as it is a non-linear model, while SVC is a linear model. ", "cell_type": "markdown", "metadata": {}}, {"source": "### Ensemble Methods - Using Adaboost", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "metadata": {}, "outputs": [], "source": "from sklearn.ensemble import AdaBoostClassifier\n#svc=SVC(probability=True, kernel='linear')\nclf_ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.5)\nmodel_ada = clf_ada.fit(x_train, y_train)\ny_pred_ada = model_ada.predict(x_test)\n"}, {"execution_count": 9, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Prediction using Adaboost\nAccuracy 0.52 Score 0.556\n"}], "source": "#Adaboost with RandomForests\nacc_ada = accuracy_score(y_pred_ada,y_test)\nscores_ada = cross_val_score(clf_ada, x_train, y_train, cv=10)\n\n#Getting the mean scores for the cross validation\nscores_ada_mean = scores_ada.mean()\n\nprint('Prediction using Adaboost')\nprint(\"Accuracy\",'%.2f'%acc_ada, \"Score\", '%.3f'%scores_ada_mean)"}, {"source": "### Deep Learning Model", "cell_type": "markdown", "metadata": {}}, {"source": "Using neural networks to classify the outcome of a match. Here, we are using a multi-layer perceptron (MLP) for multi-class classification", "cell_type": "markdown", "metadata": {}}, {"source": "### Iteration 1: Feature Creation\nNeural networks only accept numerical inputs and outputs, thus we use one hot encoding to transform the labels\n\nWe first tranform the labels into integers. Later we will use keras to_categorical to transform into binary values.\n\nThe encoding is as follows: <br/>\nWin by away team = 0 <br/>\nDraw = 1 <br/>\nWin by home team = 2 <br/>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "metadata": {}, "outputs": [{"execution_count": 10, "metadata": {}, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>home_attack_score_analysis</th>\n      <th>away_attack_score_analysis</th>\n      <th>home_defense_score_analysis</th>\n      <th>away_defense_score_analysis</th>\n      <th>home_attack_efficiency_analysis</th>\n      <th>away_attack_efficiency_analysis</th>\n      <th>home_inv_defense_efficiency_analysis</th>\n      <th>away_inv_defense_efficiency_analysis</th>\n      <th>diff_attack</th>\n      <th>diff_defense</th>\n      <th>overall_score</th>\n      <th>FT_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.367044</td>\n      <td>-0.097585</td>\n      <td>-0.143126</td>\n      <td>0.377551</td>\n      <td>-0.241390</td>\n      <td>-0.463096</td>\n      <td>-0.722440</td>\n      <td>-0.621563</td>\n      <td>-0.269459</td>\n      <td>0.520677</td>\n      <td>0.251218</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.855378</td>\n      <td>2.162607</td>\n      <td>-0.614336</td>\n      <td>-2.168971</td>\n      <td>0.418593</td>\n      <td>0.998026</td>\n      <td>-0.438074</td>\n      <td>-1.517423</td>\n      <td>-1.307229</td>\n      <td>-1.554635</td>\n      <td>-2.861864</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.076383</td>\n      <td>-0.544953</td>\n      <td>0.074727</td>\n      <td>0.420843</td>\n      <td>-0.483306</td>\n      <td>-1.066144</td>\n      <td>-0.439501</td>\n      <td>-1.018328</td>\n      <td>0.621337</td>\n      <td>0.346116</td>\n      <td>0.967453</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.167449</td>\n      <td>-0.614544</td>\n      <td>-1.192720</td>\n      <td>-0.411329</td>\n      <td>1.120426</td>\n      <td>-0.396703</td>\n      <td>-0.398956</td>\n      <td>-0.544577</td>\n      <td>2.781993</td>\n      <td>0.781391</td>\n      <td>3.563383</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.268881</td>\n      <td>1.670617</td>\n      <td>0.067824</td>\n      <td>-1.633356</td>\n      <td>-0.334656</td>\n      <td>0.369332</td>\n      <td>-0.166129</td>\n      <td>-0.043594</td>\n      <td>-1.939499</td>\n      <td>-1.701180</td>\n      <td>-3.640678</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   home_attack_score_analysis  away_attack_score_analysis  \\\n0                   -0.367044                   -0.097585   \n1                    0.855378                    2.162607   \n2                    0.076383                   -0.544953   \n3                    2.167449                   -0.614544   \n4                   -0.268881                    1.670617   \n\n   home_defense_score_analysis  away_defense_score_analysis  \\\n0                    -0.143126                     0.377551   \n1                    -0.614336                    -2.168971   \n2                     0.074727                     0.420843   \n3                    -1.192720                    -0.411329   \n4                     0.067824                    -1.633356   \n\n   home_attack_efficiency_analysis  away_attack_efficiency_analysis  \\\n0                        -0.241390                        -0.463096   \n1                         0.418593                         0.998026   \n2                        -0.483306                        -1.066144   \n3                         1.120426                        -0.396703   \n4                        -0.334656                         0.369332   \n\n   home_inv_defense_efficiency_analysis  away_inv_defense_efficiency_analysis  \\\n0                             -0.722440                             -0.621563   \n1                             -0.438074                             -1.517423   \n2                             -0.439501                             -1.018328   \n3                             -0.398956                             -0.544577   \n4                             -0.166129                             -0.043594   \n\n   diff_attack  diff_defense  overall_score  FT_encoded  \n0    -0.269459      0.520677       0.251218           1  \n1    -1.307229     -1.554635      -2.861864           0  \n2     0.621337      0.346116       0.967453           1  \n3     2.781993      0.781391       3.563383           1  \n4    -1.939499     -1.701180      -3.640678           1  "}, "output_type": "execute_result"}], "source": "full_time = df_data_1['FTR']\nanalysis_NN = df_data_1.copy()\n\nfrom sklearn.preprocessing import LabelEncoder\n# integer encode\nlabel_encoder = LabelEncoder()\nFT_encoded = label_encoder.fit_transform(full_time)\nanalysis_NN['FT_encoded'] = FT_encoded\n\n#drop all non numerical values\nanalysis_NN = analysis_NN.drop(['HomeTeam','AwayTeam','FTR'], axis=1)\nanalysis_NN.head()"}, {"execution_count": 11, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}, {"output_type": "stream", "name": "stdout", "text": "5150\n"}], "source": "from keras.utils import to_categorical\nx_all = analysis_NN.drop(['FT_encoded'], axis=1)\n#to_categorical converts integers into binary values\ny_all = to_categorical(analysis_NN['FT_encoded'])\nprint(analysis_NN.shape[0])"}, {"source": "We want to keep 20% of the data for manual cross validation, so we split the data into training and testing sets. <br/>\n20% of 5150 is 1030 <br/>\n5150 - 1030 is 4120 <br/>\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "metadata": {}, "outputs": [], "source": "x_train = x_all[:4120]\nx_test = x_all[-1030:]\ny_train = y_all[:4120]\ny_test = y_all[-1030:]\nx_train_v = x_train.values\nx_test_v = x_test.values"}, {"source": "### Deep Learning Model Training", "cell_type": "markdown", "metadata": {}}, {"source": "Now, we will define and train a neural network with 4 layers. <br/>\nIn the first layer, we must specify the expected input data shape. Since we have 9 features, the input dimension is 9.  <br/>\nThe final layer has 3 nodes, as there are only 3 outputs (Away win, Draw, Home win). <br/>\nWe will use the categorical crossentropy loss function to evaluate our model performance. \n", "cell_type": "markdown", "metadata": {}}, {"execution_count": 14, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Train on 2884 samples, validate on 1236 samples\nEpoch 1/20\n2884/2884 [==============================] - 0s - loss: 1.1208 - acc: 0.4227 - val_loss: 1.0719 - val_acc: 0.4442\nEpoch 2/20\n2884/2884 [==============================] - 0s - loss: 1.0505 - acc: 0.4771 - val_loss: 1.0686 - val_acc: 0.4442\nEpoch 3/20\n2884/2884 [==============================] - 0s - loss: 1.0488 - acc: 0.4771 - val_loss: 1.0634 - val_acc: 0.4442\nEpoch 4/20\n2884/2884 [==============================] - 0s - loss: 1.0457 - acc: 0.4771 - val_loss: 1.0629 - val_acc: 0.4442\nEpoch 5/20\n2884/2884 [==============================] - 0s - loss: 1.0434 - acc: 0.4771 - val_loss: 1.0599 - val_acc: 0.4442\nEpoch 6/20\n2884/2884 [==============================] - 0s - loss: 1.0407 - acc: 0.4771 - val_loss: 1.0571 - val_acc: 0.4442\nEpoch 7/20\n2884/2884 [==============================] - 0s - loss: 1.0377 - acc: 0.4771 - val_loss: 1.0533 - val_acc: 0.4442\nEpoch 8/20\n2884/2884 [==============================] - 0s - loss: 1.0348 - acc: 0.4771 - val_loss: 1.0503 - val_acc: 0.4442\nEpoch 9/20\n2884/2884 [==============================] - 0s - loss: 1.0307 - acc: 0.4771 - val_loss: 1.0461 - val_acc: 0.4442\nEpoch 10/20\n2884/2884 [==============================] - 0s - loss: 1.0263 - acc: 0.4771 - val_loss: 1.0418 - val_acc: 0.4442\nEpoch 11/20\n2884/2884 [==============================] - 0s - loss: 1.0216 - acc: 0.4771 - val_loss: 1.0362 - val_acc: 0.4442\nEpoch 12/20\n2884/2884 [==============================] - 0s - loss: 1.0168 - acc: 0.4792 - val_loss: 1.0316 - val_acc: 0.4450\nEpoch 13/20\n2884/2884 [==============================] - 0s - loss: 1.0108 - acc: 0.4823 - val_loss: 1.0264 - val_acc: 0.4490\nEpoch 14/20\n2884/2884 [==============================] - 0s - loss: 1.0047 - acc: 0.4917 - val_loss: 1.0196 - val_acc: 0.4830\nEpoch 15/20\n2884/2884 [==============================] - 0s - loss: 0.9987 - acc: 0.5298 - val_loss: 1.0140 - val_acc: 0.4968\nEpoch 16/20\n2884/2884 [==============================] - 0s - loss: 0.9921 - acc: 0.5260 - val_loss: 1.0076 - val_acc: 0.5202\nEpoch 17/20\n2884/2884 [==============================] - 0s - loss: 0.9869 - acc: 0.5312 - val_loss: 1.0019 - val_acc: 0.5275\nEpoch 18/20\n2884/2884 [==============================] - 0s - loss: 0.9810 - acc: 0.5350 - val_loss: 0.9966 - val_acc: 0.5324\nEpoch 19/20\n2884/2884 [==============================] - 0s - loss: 0.9760 - acc: 0.5385 - val_loss: 0.9937 - val_acc: 0.5324\nEpoch 20/20\n2884/2884 [==============================] - 0s - loss: 0.9720 - acc: 0.5388 - val_loss: 0.9894 - val_acc: 0.5340\n"}, {"execution_count": 14, "metadata": {}, "data": {"text/plain": "<keras.callbacks.History at 0x7fc17b955400>"}, "output_type": "execute_result"}], "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras import metrics\n\nmodel = Sequential()\n# Dense(64) is a fully-connected layer with 64 hidden units.\nmodel.add(Dense(64, input_dim=11))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(32, activation='sigmoid'))\nmodel.add(Dense(10, activation='sigmoid'))\nmodel.add(Dense(3, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\nmodel.fit(x_train_v, y_train,epochs=20, batch_size=128, validation_split=0.3)"}, {"source": "From the training results, we can see that the accuracy at the last epoch is 54%, while the cross validation accuracy is 53%. The performance is slightly better than the non deep learning based classifiers. We shall investigate how to improve the performance. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 15, "cell_type": "code", "metadata": {}, "outputs": [], "source": "y_pred = model.predict(x_test_v)"}, {"execution_count": 16, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[[ 0.12992436  0.21971498  0.65036064]\n [ 0.3853341   0.26531795  0.34934795]\n [ 0.35837227  0.26998004  0.37164766]\n ..., \n [ 0.23807357  0.2582016   0.50372487]\n [ 0.43744841  0.26197335  0.30057815]\n [ 0.24788913  0.25905833  0.49305257]]\n"}], "source": "print(y_pred)"}, {"execution_count": 31, "cell_type": "code", "metadata": {}, "outputs": [{"execution_count": 31, "metadata": {}, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>home_attack_score_analysis</th>\n      <th>away_attack_score_analysis</th>\n      <th>home_defense_score_analysis</th>\n      <th>away_defense_score_analysis</th>\n      <th>home_attack_efficiency_analysis</th>\n      <th>away_attack_efficiency_analysis</th>\n      <th>home_inv_defense_efficiency_analysis</th>\n      <th>away_inv_defense_efficiency_analysis</th>\n      <th>diff_attack</th>\n      <th>diff_defense</th>\n      <th>overall_score</th>\n      <th>y_pred</th>\n      <th>y_actual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4120</th>\n      <td>1.790389</td>\n      <td>-0.753725</td>\n      <td>-1.656020</td>\n      <td>-0.159273</td>\n      <td>0.202558</td>\n      <td>0.037929</td>\n      <td>-0.187167</td>\n      <td>-0.660861</td>\n      <td>2.544114</td>\n      <td>1.496748</td>\n      <td>4.040862</td>\n      <td>H</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>4121</th>\n      <td>-0.538829</td>\n      <td>0.909730</td>\n      <td>0.084051</td>\n      <td>-0.215602</td>\n      <td>-0.389536</td>\n      <td>2.447389</td>\n      <td>-0.550693</td>\n      <td>1.692358</td>\n      <td>-1.448559</td>\n      <td>-0.299653</td>\n      <td>-1.748212</td>\n      <td>A</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4122</th>\n      <td>1.310207</td>\n      <td>2.162607</td>\n      <td>-1.076366</td>\n      <td>-2.168971</td>\n      <td>-0.216535</td>\n      <td>0.998026</td>\n      <td>-0.858941</td>\n      <td>-1.517423</td>\n      <td>-0.852399</td>\n      <td>-1.092606</td>\n      <td>-1.945005</td>\n      <td>H</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>4123</th>\n      <td>-0.675088</td>\n      <td>0.368281</td>\n      <td>0.112023</td>\n      <td>-1.208595</td>\n      <td>0.374926</td>\n      <td>-0.137045</td>\n      <td>1.434206</td>\n      <td>-0.827881</td>\n      <td>-1.043369</td>\n      <td>-1.320618</td>\n      <td>-2.363988</td>\n      <td>A</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>4124</th>\n      <td>2.316548</td>\n      <td>1.849993</td>\n      <td>-1.534492</td>\n      <td>-1.451840</td>\n      <td>0.589495</td>\n      <td>0.835882</td>\n      <td>-0.553050</td>\n      <td>-0.434561</td>\n      <td>0.466555</td>\n      <td>0.082652</td>\n      <td>0.549207</td>\n      <td>H</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "      home_attack_score_analysis  away_attack_score_analysis  \\\n4120                    1.790389                   -0.753725   \n4121                   -0.538829                    0.909730   \n4122                    1.310207                    2.162607   \n4123                   -0.675088                    0.368281   \n4124                    2.316548                    1.849993   \n\n      home_defense_score_analysis  away_defense_score_analysis  \\\n4120                    -1.656020                    -0.159273   \n4121                     0.084051                    -0.215602   \n4122                    -1.076366                    -2.168971   \n4123                     0.112023                    -1.208595   \n4124                    -1.534492                    -1.451840   \n\n      home_attack_efficiency_analysis  away_attack_efficiency_analysis  \\\n4120                         0.202558                         0.037929   \n4121                        -0.389536                         2.447389   \n4122                        -0.216535                         0.998026   \n4123                         0.374926                        -0.137045   \n4124                         0.589495                         0.835882   \n\n      home_inv_defense_efficiency_analysis  \\\n4120                             -0.187167   \n4121                             -0.550693   \n4122                             -0.858941   \n4123                              1.434206   \n4124                             -0.553050   \n\n      away_inv_defense_efficiency_analysis  diff_attack  diff_defense  \\\n4120                             -0.660861     2.544114      1.496748   \n4121                              1.692358    -1.448559     -0.299653   \n4122                             -1.517423    -0.852399     -1.092606   \n4123                             -0.827881    -1.043369     -1.320618   \n4124                             -0.434561     0.466555      0.082652   \n\n      overall_score y_pred y_actual  \n4120       4.040862      H        H  \n4121      -1.748212      A        A  \n4122      -1.945005      H        H  \n4123      -2.363988      A        D  \n4124       0.549207      H        A  "}, "output_type": "execute_result"}], "source": "import numpy as np\ny_pred_int = np.argmax(y_pred, axis=1)\ny_actual_int = np.argmax(y_test, axis=1)\n\n#Encode back into ADH form\ny_pred_encode = pd.cut(y_pred_int,3, labels=[\"A\", \"D\", \"H\"])\ny_actual_encode = pd.cut(y_actual_int,3, labels=[\"A\", \"D\", \"H\"])\n\nfinal_predict_NN = x_test.copy()\nfinal_predict_NN['y_pred'] = y_pred_encode\nfinal_predict_NN['y_actual'] = y_actual_encode\nfinal_predict_NN.head()"}, {"execution_count": 32, "cell_type": "code", "metadata": {}, "outputs": [{"execution_count": 32, "metadata": {}, "data": {"text/plain": "array([[174,   0, 130],\n       [ 62,   0, 182],\n       [ 76,   0, 406]])"}, "output_type": "execute_result"}], "source": "from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_actual_encode, y_pred_encode, labels=[\"A\", \"D\", \"H\"])"}, {"execution_count": 33, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy = 0.5631067961165048\n"}], "source": "#Accuracy Scoring\ncount = 0\nif len(y_pred_encode) == len(y_actual_encode):\n    for i in range(len(y_pred_encode)):\n        if y_pred_encode[i] == y_actual_encode[i]:\n             count += 1\n\nprint(\"Accuracy = \" + str(count*1.0/1030))"}, {"source": "Our Neural Network has a tendency to predict home wins and away wins, but not draws. This is because our current approach chooses the class with the highest probability.\n\nFor instance, if the predicted probabilities are [0.37, 0.28, 0.34] , the neural network will predict the class of probability 0.37, which is an away win. This is clearly incorrect, as the difference between a home win (0.34) and a away win (0.37) is small.", "cell_type": "markdown", "metadata": {}}, {"source": "### Approach for predicting draws", "cell_type": "markdown", "metadata": {}}, {"source": "We set a threshold value equal to 0.05. We then check for the difference in predicted probabilies between away win and home win. If the difference is less than the threshold value, then we predict a draw.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 34, "cell_type": "code", "metadata": {}, "outputs": [], "source": "threshold = 0.05\ncount_1 = 0\nfor row in y_pred:\n    diff = abs(row[2] - row[0])\n    if (diff<threshold):\n        y_pred_encode[count_1] = 'D'\n    count_1 += 1"}, {"execution_count": 35, "cell_type": "code", "metadata": {}, "outputs": [{"execution_count": 35, "metadata": {}, "data": {"text/plain": "array([[168,  16, 120],\n       [ 59,   9, 176],\n       [ 72,  15, 395]])"}, "output_type": "execute_result"}], "source": "from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_actual_encode, y_pred_encode, labels=[\"A\", \"D\", \"H\"])"}, {"execution_count": 36, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy = 0.5553398058252427\n"}], "source": "#New Accuracy\ncount_2 = 0\nif len(y_pred_encode) == len(y_actual_encode):\n    for i in range(len(y_pred_encode)):\n        if y_pred_encode[i] == y_actual_encode[i]:\n             count_2 += 1\n\nprint(\"Accuracy = \" + str(count_2*1.0/1030))"}, {"source": "### Final Model Evaluation", "cell_type": "markdown", "metadata": {}}, {"source": "In summary, for non deep learning based models, the SVC Classifier and the ensemble based method with Adaboost provides the highest accuracy at 52%. On the other hand, for a deep learning based neural network, the accuracy is around 54-55%. Although this may seem like a low figure, it turns out the world's most established football bookmakers, such as Bet365, have a betting accuracy of around 53%. In a football match, numerous factors, such as weather conditions, cannot be accounted for, giving rise to inaccuracies in the prediction. Besides, with some additional modifications, our neural network now has the ability to predict draws as well. Thus, we will choose the neural network model for use in predictions. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}